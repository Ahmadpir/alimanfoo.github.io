{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last year a colleague pointed me at [Richard Durbin's 2014 paper on the positional Burrows Wheeler transform](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3998136/). I read it with interest but didn't really get it at the time. Recently there have been papers developing PBWT for [variation graphs](http://biorxiv.org/content/early/2016/05/02/051409.abstract) and [chromosome painting](http://biorxiv.org/content/early/2016/04/12/048280.abstract). Given the applicability of PBWT to a range of problems, I wanted to try and wrap my head around it. This notebook is an attempt to understand the basic algorithms described in Durbin (2014), I wrote it for my own benefit but thought I'd share in case it's useful to anyone and/or anyone might be able to help me fill in some of the gaps.\n",
    "\n",
    "*2016-06-23: Updated implementation of algorithm 4 to avoid reporting 0 length matches. Also added some discussion of the value of using PBWT to improve compressibility of haplotype data versus simply transposing the haplotypes so the data are organised one variant per row.*\n",
    "\n",
    "Let's start with some data. The variable *X* below is a list of 8 haplotypes with 6 variable sites, all biallelic. This is just some dummy data I made up myself to test out the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [[0, 1, 0, 1, 0, 1],\n",
    "     [1, 1, 0, 0, 0, 1],\n",
    "     [1, 1, 1, 1, 1, 1],\n",
    "     [0, 1, 1, 1, 1, 0],\n",
    "     [0, 0, 0, 0, 0, 0],\n",
    "     [1, 0, 0, 0, 1, 0],\n",
    "     [1, 1, 0, 0, 0, 1],\n",
    "     [0, 1, 0, 1, 1, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 1. Build prefix array\n",
    "\n",
    "The basic idea of PBWT is to sort the haplotypes in order of reversed prefixes. This sorting then enables matches between haplotypes to be found efficiently. Algorithm 1 in Durbin (2014) builds something called the \"positional prefix array\", which is just the list of haplotype indices that would sort the haplotypes in reversed prefix order at some position *k*. \n",
    "\n",
    "Durbin uses the notation *a<sub>k</sub>* to denote the positional prefix array for position *k*, however he also uses the variable *a* for one of the intermediates within algorithm 1, so to avoid any ambiguity here I will use *ppa<sub>k</sub>* to denote the positional prefix array at position *k*.\n",
    "\n",
    "The trick of algorithm 1 is to sweep through the data by position, building *ppa<sub>k+1</sub>* from *ppa<sub>k</sub>*. The algorithm simply sorts the haplotypes by allele at position *k*, making sure that the sort order from the previous position is retained for all haplotypes with the same allele value.\n",
    "\n",
    "Here is a pure Python implementation of algorithm 1, purely for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_prefix_array(X):\n",
    "    \n",
    "    # M haplotypes\n",
    "    M = len(X)\n",
    "\n",
    "    # N variable sites\n",
    "    N = len(X[0])\n",
    "    \n",
    "    # initialise positional prefix array\n",
    "    ppa = list(range(M))\n",
    "    \n",
    "    # iterate over variants\n",
    "    for k in range(N-1):\n",
    "\n",
    "        # setup intermediates\n",
    "        a = list()\n",
    "        b = list()\n",
    "    \n",
    "        # iterate over haplotypes in reverse prefix sorted order\n",
    "        for index in ppa:\n",
    "\n",
    "            # current haplotype\n",
    "            haplotype = X[index]\n",
    "            \n",
    "            # allele for current haplotype\n",
    "            allele = haplotype[k]\n",
    "            \n",
    "            # update intermediates\n",
    "            if allele == 0:\n",
    "                a.append(index)\n",
    "            else:\n",
    "                b.append(index)\n",
    "                \n",
    "        # construct the new positional prefix array for k+1 by concatenating lists a and b\n",
    "        ppa = a + b\n",
    "        \n",
    "    return ppa\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on the dummy data *X*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 6, 0, 5, 7, 3, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_prefix_array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting list of integers is the list of haplotype indices that sorts the haplotypes up to the final position (*k* = *N*-1). To help visualise this, let's write a display function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_prefix_array(X):\n",
    "    from IPython.display import display_html\n",
    "    ppa = build_prefix_array(X)\n",
    "    html = '<pre style=\"line-height: 100%\">'\n",
    "    for index in ppa:\n",
    "        haplotype = X[index]\n",
    "        html += str(index) + '|' + ''.join(str(allele) for allele in haplotype[:-1])\n",
    "        html += '  ' + str(haplotype[-1]) + '<br/>'\n",
    "    html += '</pre>'\n",
    "    display_html(html, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\">4|00000  0<br/>1|11000  1<br/>6|11000  1<br/>0|01010  1<br/>5|10001  0<br/>7|01011  0<br/>3|01111  0<br/>2|11111  1<br/></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_prefix_array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positional prefix array [4, 1, 6, ...] is the column to the left of the '``|``' showing the haplotype indices. To the right of the '``|``' are the haplotypes up to *k*-1 sorted in reversed prefix order. Then separated by a space is the next allele for each haplotype - this final column makes up what Durbin (2014) calls *y<sup>k</sup>*[*k*]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 2. Build prefix and divergence arrays\n",
    "\n",
    "Sorting haplotypes in this order has a very useful property, which is that each haplotype will be adjacent to the haplotype with the longest match. If several haplotypes have equally long matches these will all be adjacent. Also, the length of match between any pair of non-adjacent haplotypes is the minimum of the lengths of the matches between all haplotypes occurring in between them in the sorted order.\n",
    "\n",
    "Algorithm 2 shows how to find and keep track of the start position for matches between adjacent haplotypes. This can be done while sweeping through the data building the positional prefix arrays. The reason this is possible is because once a match begins between a pair of adjacent haplotypes, those two haplotypes will remain adjacent until the match breaks.\n",
    "\n",
    "Here's a pure Python implementation of algorithm 2, again purely for illustration. Durbin (2014) uses *d<sub>k</sub>* to denote the \"divergence array\" at position *k*, where *d<sub>k</sub>*[*i*] is the position where a match begins between the *i*th haplotype in the sorted order and it's predecessor. Because *d* is also used for one of the intermediates, for clarity I'll use *div<sub>k</sub>* to denote the divergence array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_prefix_and_divergence_arrays(X):\n",
    "    \n",
    "    # M haplotypes\n",
    "    M = len(X)\n",
    "\n",
    "    # N variable sites\n",
    "    N = len(X[0])\n",
    "    \n",
    "    # initialise positional prefix array\n",
    "    ppa = list(range(M))\n",
    "    \n",
    "    # initialise divergence array\n",
    "    div = [0] * M\n",
    "    \n",
    "    # iterate over variants\n",
    "    for k in range(N-1):\n",
    "\n",
    "        # setup intermediates\n",
    "        a = list()\n",
    "        b = list()\n",
    "        d = list()\n",
    "        e = list()\n",
    "        p = q = k + 1\n",
    "    \n",
    "        # iterate over haplotypes in reverse prefix sorted order\n",
    "        for index, match_start in zip(ppa, div):\n",
    "\n",
    "            # current haplotype\n",
    "            haplotype = X[index]\n",
    "            \n",
    "            # allele for current haplotype\n",
    "            allele = haplotype[k]\n",
    "            \n",
    "            # update intermediates\n",
    "            if match_start > p:\n",
    "                p = match_start\n",
    "            if match_start > q:\n",
    "                q = match_start\n",
    "\n",
    "            # update intermediates\n",
    "            if allele == 0:\n",
    "                a.append(index)\n",
    "                d.append(p)\n",
    "                p = 0\n",
    "            else:\n",
    "                b.append(index)\n",
    "                e.append(q)\n",
    "                q = 0\n",
    "                \n",
    "        # construct the new arrays for k+1 by concatenating intermediates\n",
    "        ppa = a + b\n",
    "        div = d + e\n",
    "        \n",
    "    return ppa, div\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on the dummy haplotype data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppa, div = build_prefix_and_divergence_arrays(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 6, 0, 5, 7, 3, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 0, 4, 5, 4, 3, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again to help make sense of this let's write a display function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_prefix_and_divergence_arrays(X):\n",
    "    from IPython.display import display_html\n",
    "    ppa, div = build_prefix_and_divergence_arrays(X)\n",
    "    html = '<pre style=\"line-height: 100%\">'\n",
    "    for index, match_start in zip(ppa, div):\n",
    "        haplotype = X[index]\n",
    "        html += str(index) + '|'\n",
    "        for k, allele in enumerate(haplotype[:-1]):\n",
    "            if match_start == k:\n",
    "                html += '<strong><u>'\n",
    "            html += str(allele)\n",
    "        if match_start < len(haplotype) - 1:\n",
    "            html += '</u></strong>'\n",
    "        html += '  ' + str(haplotype[-1]) + '<br/>'\n",
    "    html += '</pre>'\n",
    "    display_html(html, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\">4|00000  0<br/>1|11<strong><u>000</u></strong>  1<br/>6|<strong><u>11000</u></strong>  1<br/>0|0101<strong><u>0</u></strong>  1<br/>5|10001  0<br/>7|0101<strong><u>1</u></strong>  0<br/>3|011<strong><u>11</u></strong>  0<br/>2|1<strong><u>1111</u></strong>  1<br/></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_prefix_and_divergence_arrays(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The divergence array has been used to show underlined in bold the maximal matches between each haplotype and it's predecessor in the sorted order, as in Durbin (2014) Figure 1. \n",
    "\n",
    "Let's try it out on some randomly generated data, just to have another example to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\">1|11001011100011111101111000000  0<br/>9|110011011011110110010000101<strong><u>00</u></strong>  0<br/>8|11110001100100100111000001<strong><u>100</u></strong>  1<br/>4|1001111111010100011011101<strong><u>1100</u></strong>  1<br/>5|1111100110101000101000001011<strong><u>0</u></strong>  1<br/>2|00101000111100110011101010001  0<br/>6|11010001100000001<strong><u>011101010001</u></strong>  0<br/>7|10010110111010100000000011<strong><u>001</u></strong>  1<br/>3|000100011111000110110101101<strong><u>01</u></strong>  1<br/>0|1101011111011010001101001111<strong><u>1</u></strong>  0<br/></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "M = 10\n",
    "N = 30\n",
    "Y = [[random.randint(0, 1) for _ in range(N)] for _ in range(M)]\n",
    "display_prefix_and_divergence_arrays(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 3. Report long matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 3 shows how to find all matches between haplotypes longer than some value *L*. The trick here is to notice that all haplotypes with matches longer than L will be adjacent in the sorted order, forming a \"block\". So algorithm 3 iterates over the haplotypes in sorted order, collecting haplotypes with matches longer than L. When it finds a match less than *L*, it must mean a break between blocks, so it reports matches for all haplotypes in the previous block. The algorithm also collects separately for haplotypes with different alleles at position *k*, to ensure that only matches that terminate at *k* are reported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_long_matches(X, L):\n",
    "    \n",
    "    # M haplotypes\n",
    "    M = len(X)\n",
    "\n",
    "    # N variable sites\n",
    "    N = len(X[0])\n",
    "    \n",
    "    # initialise positional prefix array\n",
    "    ppa = list(range(M))\n",
    "    \n",
    "    # initialise divergence array\n",
    "    div = [0] * M\n",
    "    \n",
    "    # iterate over variants\n",
    "    for k in range(N):\n",
    "\n",
    "        # setup intermediates\n",
    "        a = list()\n",
    "        b = list()\n",
    "        d = list()\n",
    "        e = list()\n",
    "        p = q = k + 1\n",
    "        ma = list()\n",
    "        mb = list()\n",
    "    \n",
    "        # iterate over haplotypes in reverse prefix sorted order\n",
    "        for index, match_start in zip(ppa, div):\n",
    "            \n",
    "            # report matches\n",
    "            if match_start > k - L:\n",
    "                if ma and mb:\n",
    "                    yield k, ma, mb\n",
    "                ma = list()\n",
    "                mb = list()\n",
    "\n",
    "            # current haplotype\n",
    "            haplotype = X[index]\n",
    "            \n",
    "            # allele for current haplotype\n",
    "            allele = haplotype[k]\n",
    "            \n",
    "            # update intermediates\n",
    "            if match_start > p:\n",
    "                p = match_start\n",
    "            if match_start > q:\n",
    "                q = match_start\n",
    "\n",
    "            # update intermediates\n",
    "            if allele == 0:\n",
    "                a.append(index)\n",
    "                d.append(p)\n",
    "                p = 0\n",
    "                ma.append(index)\n",
    "            else:\n",
    "                b.append(index)\n",
    "                e.append(q)\n",
    "                q = 0\n",
    "                mb.append(index)\n",
    "                \n",
    "        # report any remaining matches including final haplotype (N.B., not in Durbin 2014)\n",
    "        if ma and mb:\n",
    "            yield k, ma, mb\n",
    "                \n",
    "        # construct the new arrays for k+1\n",
    "        if k < N - 1:\n",
    "            ppa = a + b\n",
    "            div = d + e\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One minor note, I don't think algorithm 3 as presented in Durbin (2014) accounts for the case where a block of matching haplotypes extends up to the final haplotype, so I added in an extra couple of lines to account for this case.\n",
    "\n",
    "Let's try it out on the dummy data, finding matches 3 or longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, [4], [5])\n",
      "(4, [0], [7])\n",
      "(5, [4], [1, 6])\n",
      "(5, [3], [2])\n"
     ]
    }
   ],
   "source": [
    "for match in report_long_matches(X, 3):\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 4 matches have been found. The first match terminates at position 4, and is between haplotypes 4 and 5. Again let's write a display function to help visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_long_matches(X, L):\n",
    "    from IPython.display import display_html\n",
    "    html = '<pre style=\"line-height: 100%\">'\n",
    "    for match in report_long_matches(X, L):\n",
    "        k, ma, mb = match\n",
    "        for i in sorted(ma):\n",
    "            for j in sorted(mb):\n",
    "                html += 'match ending at position %s between haplotypes %s and %s:<br/><br/>' % (k, i, j)\n",
    "                h1 = X[i][k-L:k+1]\n",
    "                h2 = X[j][k-L:k+1]\n",
    "                html += str(i) + '|' + ''.join(str(allele) for allele in h1[:-1]) \n",
    "                html += str(h1[-1]) + '<br/>'\n",
    "                html += str(j) + '|<strong><u>' + ''.join(str(allele) for allele in h2[:-1]) + '</u></strong>'\n",
    "                html += str(h2[-1]) + '<br/><br/>'\n",
    "    html += '</pre>'\n",
    "    display_html(html, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\">match ending at position 4 between haplotypes 4 and 5:<br/><br/>4|0000<br/>5|<strong><u>000</u></strong>1<br/><br/>match ending at position 4 between haplotypes 0 and 7:<br/><br/>0|1010<br/>7|<strong><u>101</u></strong>1<br/><br/>match ending at position 5 between haplotypes 4 and 1:<br/><br/>4|0000<br/>1|<strong><u>000</u></strong>1<br/><br/>match ending at position 5 between haplotypes 4 and 6:<br/><br/>4|0000<br/>6|<strong><u>000</u></strong>1<br/><br/>match ending at position 5 between haplotypes 3 and 2:<br/><br/>3|1110<br/>2|<strong><u>111</u></strong>1<br/><br/></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_long_matches(X, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\">match ending at position 4 between haplotypes 0 and 7:<br/><br/>0|01010<br/>7|<strong><u>0101</u></strong>1<br/><br/>match ending at position 5 between haplotypes 3 and 2:<br/><br/>3|11110<br/>2|<strong><u>1111</u></strong>1<br/><br/></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_long_matches(X, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\"></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_long_matches(X, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the dummy data *X* contains two haplotypes that are completely identical over all 6 positions, so why aren't these found? That's because the algorithm requires matches to terminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 4. Report set maximal matches\n",
    "\n",
    "Algorithm 4 shows how to find \"set maximal matches\" for each haplotype. These are the longest match for each haplotype at each position *k*. Again this makes use of the fact that haplotypes with maximal matches will be adjacent in the sorted order. At each position *k*, the algorithm iterates through the haplotypes in sorted order, looking for a maximal match for each haplotype. The first thing it does is to try and find any neighbours where the match can be extended, i.e., where the alleles at position *k* are the same. If so, continue on to the next haplotype without reporting anything. Otherwise, report a match with the longest matching neighbour (taking into account the fact that several neighbours may have equally long matches). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_set_maximal_matches(X):\n",
    "\n",
    "    # M haplotypes\n",
    "    M = len(X)\n",
    "\n",
    "    # N variable sites\n",
    "    N = len(X[0])\n",
    "    \n",
    "    # initialise positional prefix array\n",
    "    ppa = list(range(M))\n",
    "    \n",
    "    # initialise divergence array\n",
    "    div = [0] * M\n",
    "    \n",
    "    # iterate over variants\n",
    "    for k in range(N):\n",
    "        \n",
    "        # sentinel\n",
    "        div.append(k+1)\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            m = i - 1\n",
    "            n = i + 1\n",
    "            match_continues = False\n",
    "            \n",
    "            if div[i] <= div[i+1]:\n",
    "                # match to previous neighbour is longer, scan \"down\" the haplotypes (decreasing indices)\n",
    "                while div[m+1] <= div[i]:\n",
    "                    if X[ppa[m]][k] == X[ppa[i]][k]:\n",
    "                        match_continues = True\n",
    "                        break\n",
    "                    m -= 1\n",
    "            if match_continues:\n",
    "                continue\n",
    "                    \n",
    "            if div[i] >= div[i+1]:\n",
    "                # match to next neighbour is longer, scan \"up\" the haplotypes (increasing indices)\n",
    "                while div[n] <= div[i+1]:\n",
    "                    if X[ppa[n]][k] == X[ppa[i]][k]:\n",
    "                        match_continues = True\n",
    "                        break\n",
    "                    n += 1\n",
    "            if match_continues:\n",
    "                continue\n",
    "                \n",
    "            for j in range(m+1, i):\n",
    "                if div[i] < k:  # N.B., avoid 0 length matches, not in Durbin (2014)\n",
    "                    yield ppa[i], ppa[j], div[i], k\n",
    "                \n",
    "            for j in range(i+1, n):\n",
    "                if div[i+1] < k:  # N.B., avoid 0 length matches, not in Durbin (2014)\n",
    "                    yield ppa[i], ppa[j], div[i+1], k\n",
    "                    \n",
    "        # build next prefix and divergence arrays\n",
    "        if k < N - 1:        \n",
    "                \n",
    "            # setup intermediates\n",
    "            a = list()\n",
    "            b = list()\n",
    "            d = list()\n",
    "            e = list()\n",
    "            p = q = k + 1\n",
    "\n",
    "            # iterate over haplotypes in prefix sorted order\n",
    "            for index, match_start in zip(ppa, div):\n",
    "\n",
    "                # current haplotype\n",
    "                haplotype = X[index]\n",
    "\n",
    "                # allele for current haplotype\n",
    "                allele = haplotype[k]\n",
    "\n",
    "                # update intermediates\n",
    "                if match_start > p:\n",
    "                    p = match_start\n",
    "                if match_start > q:\n",
    "                    q = match_start\n",
    "\n",
    "                # update intermediates\n",
    "                if allele == 0:\n",
    "                    a.append(index)\n",
    "                    d.append(p)\n",
    "                    p = 0\n",
    "                else:\n",
    "                    b.append(index)\n",
    "                    e.append(q)\n",
    "                    q = 0\n",
    "\n",
    "            # construct the new arrays for k+1\n",
    "            ppa = a + b\n",
    "            div = d + e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 0, 1)\n",
      "(4, 3, 0, 1)\n",
      "(4, 7, 0, 1)\n",
      "(5, 1, 0, 1)\n",
      "(5, 2, 0, 1)\n",
      "(5, 6, 0, 1)\n",
      "(3, 0, 0, 2)\n",
      "(3, 7, 0, 2)\n",
      "(2, 1, 0, 2)\n",
      "(2, 6, 0, 2)\n",
      "(4, 5, 1, 4)\n",
      "(5, 4, 1, 4)\n",
      "(0, 7, 0, 4)\n",
      "(7, 0, 0, 4)\n",
      "(4, 1, 2, 5)\n",
      "(4, 6, 2, 5)\n",
      "(3, 2, 1, 5)\n",
      "(2, 3, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "for match in report_set_maximal_matches(X):\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_set_maximal_matches(X):\n",
    "    from IPython.display import display_html\n",
    "    from operator import itemgetter\n",
    "    from itertools import groupby\n",
    "    html = '<pre style=\"line-height: 100%\">'\n",
    "    matches = sorted(report_set_maximal_matches(X), key=itemgetter(0, 2))\n",
    "    for i, sub_matches in groupby(matches, key=itemgetter(0)):\n",
    "        html += 'set maximal matches for haplotype %s:<br/><br/>' % i\n",
    "        hi = X[i]\n",
    "        html += str(i) + '|' + ''.join(map(str, hi)) + '<br/>'\n",
    "        for _, j, k1, k2 in sub_matches:\n",
    "            hj = X[j]\n",
    "            html += str(j) + '|' + ''.join(map(str, hj[:k1]))\n",
    "            html += '<strong><u>' + ''.join(map(str, hj[k1:k2])) + '</u></strong>'\n",
    "            html += ''.join(map(str, hj[k2:])) + '<br/>'\n",
    "        html += '<br/>'\n",
    "    html += '</pre>'\n",
    "    display_html(html, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\">set maximal matches for haplotype 0:<br/><br/>0|010101<br/>7|<strong><u>0101</u></strong>10<br/><br/>set maximal matches for haplotype 2:<br/><br/>2|111111<br/>1|<strong><u>11</u></strong>0001<br/>6|<strong><u>11</u></strong>0001<br/>3|0<strong><u>1111</u></strong>0<br/><br/>set maximal matches for haplotype 3:<br/><br/>3|011110<br/>0|<strong><u>01</u></strong>0101<br/>7|<strong><u>01</u></strong>0110<br/>2|1<strong><u>1111</u></strong>1<br/><br/>set maximal matches for haplotype 4:<br/><br/>4|000000<br/>0|<strong><u>0</u></strong>10101<br/>3|<strong><u>0</u></strong>11110<br/>7|<strong><u>0</u></strong>10110<br/>5|1<strong><u>000</u></strong>10<br/>1|11<strong><u>000</u></strong>1<br/>6|11<strong><u>000</u></strong>1<br/><br/>set maximal matches for haplotype 5:<br/><br/>5|100010<br/>1|<strong><u>1</u></strong>10001<br/>2|<strong><u>1</u></strong>11111<br/>6|<strong><u>1</u></strong>10001<br/>4|0<strong><u>000</u></strong>00<br/><br/>set maximal matches for haplotype 7:<br/><br/>7|010110<br/>0|<strong><u>0101</u></strong>01<br/><br/></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_set_maximal_matches(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the bold underline indicates the regions in the haplotype representing set maximal matches to the haplotype at the top.\n",
    "\n",
    "Again you may notice that there are no matches reported for the two haplotypes that are identical across all 6 positions. Again this is because matches are required to terminate.\n",
    "\n",
    "Let's have a look with some random data for further illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"line-height: 100%\">set maximal matches for haplotype 0:<br/><br/>0|100001010111100110111010100101<br/>2|011<strong><u>00</u></strong>0110001000111111011110011<br/>1|01101<strong><u>1</u></strong>110111001111100110000010<br/>1|0110111<strong><u>10111</u></strong>001111100110000010<br/>2|0110001100010<strong><u>0011</u></strong>1111011110011<br/>2|011000110001000111<strong><u>11101</u></strong>1110011<br/>1|0110111101110011111001<strong><u>10</u></strong>000010<br/>2|011000110001000111111011<strong><u>1</u></strong>10011<br/>1|0110111101110011111001100<strong><u>00</u></strong>010<br/><br/>set maximal matches for haplotype 1:<br/><br/>1|011011110111001111100110000010<br/>2|<strong><u>0110</u></strong>00110001000111111011110011<br/>0|10000<strong><u>1</u></strong>010111100110111010100101<br/>2|011000<strong><u>110</u></strong>001000111111011110011<br/>0|1000010<strong><u>10111</u></strong>100110111010100101<br/>2|01100011000<strong><u>100</u></strong>0111111011110011<br/>2|011000110001000<strong><u>1111</u></strong>11011110011<br/>0|1000010101111001101110<strong><u>10</u></strong>100101<br/>0|1000010101111001101110101<strong><u>00</u></strong>101<br/>2|01100011000100011111101111<strong><u>001</u></strong>1<br/><br/>set maximal matches for haplotype 2:<br/><br/>2|011000110001000111111011110011<br/>1|<strong><u>0110</u></strong>11110111001111100110000010<br/>0|100<strong><u>00</u></strong>1010111100110111010100101<br/>1|011011<strong><u>110</u></strong>111001111100110000010<br/>1|01101111011<strong><u>100</u></strong>1111100110000010<br/>0|1000010101111<strong><u>0011</u></strong>0111010100101<br/>1|011011110111001<strong><u>1111</u></strong>00110000010<br/>0|100001010111100110<strong><u>11101</u></strong>0100101<br/>0|100001010111100110111010<strong><u>1</u></strong>00101<br/>1|01101111011100111110011000<strong><u>001</u></strong>0<br/><br/></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "M = 3\n",
    "N = 30\n",
    "Y = [[random.randint(0, 1) for _ in range(N)] for _ in range(M)]\n",
    "display_set_maximal_matches(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 5. Set maximal matches from a new sequence *z* to *X*\n",
    "\n",
    "I haven't got my head around this yet. Any help with the basic intuition would be very welcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact representation of *X*\n",
    "\n",
    "I think I partly get this, at least why *PBWT* should be more compressible than the original *X*. But I don't get how you recover *X* from *PBWT*. I need to go and read up about the FM-index.\n",
    "\n",
    "Let's at least check the assertion that the *PBWT* is more compressible than *X*, using some real haplotype data from [Ag1000G](http://www.malariagen.net/ag1000g). First, I'm going to implement algorithm 2 in a slightly different way, using NumPy and Cython to speed things up, and also constructing the *PBWT* as output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "\n",
    "def build_pbwt(np.int8_t[:, :] H):\n",
    "    cdef:\n",
    "        Py_ssize_t N, M, k, i, u, v, p, q\n",
    "        np.uint32_t index, match_start\n",
    "        np.int8_t allele\n",
    "        np.int8_t[:, :] pbwt\n",
    "        np.uint32_t[:, :] ppa, div\n",
    "        np.uint32_t[:] a, b, d, e\n",
    "    \n",
    "    # expect haplotype data transposed\n",
    "    N, M = H.shape[:2]\n",
    "    \n",
    "    # setup pbwt\n",
    "    pbwt = np.empty_like(H)\n",
    "\n",
    "    # setup positional prefix array\n",
    "    ppa = np.empty((N, M), dtype='u4')\n",
    "    \n",
    "    # initialise first ppa column\n",
    "    for i in range(M):\n",
    "        ppa[0, i] = i\n",
    "    \n",
    "    # setup divergence array\n",
    "    div = np.zeros((N, M), dtype='u4')\n",
    "    \n",
    "    # setup intermediates\n",
    "    a = np.zeros(M, dtype='u4')\n",
    "    b = np.zeros(M, dtype='u4')\n",
    "    d = np.zeros(M, dtype='u4')\n",
    "    e = np.zeros(M, dtype='u4')\n",
    "    \n",
    "    # iterate over variants\n",
    "    for k in range(N):\n",
    "        \n",
    "        # setup intermediates\n",
    "        u = v = 0\n",
    "        p = q = k + 1\n",
    "    \n",
    "        # iterate over haplotypes in reverse prefix sorted order\n",
    "        for i in range(M):\n",
    "\n",
    "            # index for current haplotype\n",
    "            index = ppa[k, i]\n",
    "            \n",
    "            # match start position for current haplotype\n",
    "            match_start = div[k, i]\n",
    "            \n",
    "            # allele for current haplotype\n",
    "            allele = H[k, index]\n",
    "            \n",
    "            # update output\n",
    "            pbwt[k, i] = allele\n",
    "            \n",
    "            # update intermediates\n",
    "            if match_start > p:\n",
    "                p = match_start\n",
    "            if match_start > q:\n",
    "                q = match_start\n",
    "\n",
    "            # update intermediates\n",
    "            if allele == 0:\n",
    "                a[u] = index\n",
    "                d[u] = p\n",
    "                u += 1\n",
    "                p = 0\n",
    "            else:\n",
    "                b[v] = index\n",
    "                e[v] = q\n",
    "                v += 1\n",
    "                q = 0\n",
    "                \n",
    "        if k < N - 1:\n",
    "            \n",
    "            # construct the new positional prefix array for k+1\n",
    "            ppa[k+1, :u] = a[:u]\n",
    "            ppa[k+1, u:] = b[:v]\n",
    "        \n",
    "            # construct the new divergence array for k+1\n",
    "            div[k+1, :u] = d[:u]\n",
    "            div[k+1, u:] = e[:v]\n",
    "        \n",
    "    return np.asarray(pbwt), np.asarray(ppa), np.asarray(div)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some extra libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import allel\n",
    "import zarr\n",
    "zarr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some real haplotype data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"ag1000g.phase1.ar3.haplotypes.3R.h5\" (mode r)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset_fn = '/data/coluzzi/ag1000g/data/phase1/release/AR3/haplotypes/main/hdf5/ag1000g.phase1.ar3.haplotypes.3R.h5'\n",
    "callset = h5py.File(callset_fn, mode='r')\n",
    "callset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='petl'>\n",
       "<caption>GenotypeChunkedArray((10178802, 773, 2), int8, nbytes=14.7G, cbytes=449.7M, cratio=33.4, cname=gzip, clevel=1, shuffle=True, chunks=(678, 773, 2), data=h5py._hl.dataset.Dataset)</caption>\n",
       "<thead>\n",
       "<tr>\n",
       "<th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>2</th>\n",
       "<th>3</th>\n",
       "<th>4</th>\n",
       "<th>...</th>\n",
       "<th>768</th>\n",
       "<th>769</th>\n",
       "<th>770</th>\n",
       "<th>771</th>\n",
       "<th>772</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>...</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>1</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>...</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>2</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>...</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>3</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>...</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>4</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>...</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "<td>0/0</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<p><strong>...</strong></p>"
      ],
      "text/plain": [
       "GenotypeChunkedArray((10178802, 773, 2), int8, nbytes=14.7G, cbytes=449.7M, cratio=33.4, cname=gzip, clevel=1, shuffle=True, chunks=(678, 773, 2), data=h5py._hl.dataset.Dataset)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genotypes = allel.GenotypeChunkedArray(callset['3R/calldata/genotype'])\n",
    "genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison with results from Durbin (2014) let's take 1000 haplotypes and use the same number of segregating sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='petl'>\n",
       "<caption>HaplotypeArray((370264, 1000), dtype=int8)</caption>\n",
       "<thead>\n",
       "<tr>\n",
       "<th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>2</th>\n",
       "<th>3</th>\n",
       "<th>4</th>\n",
       "<th>...</th>\n",
       "<th>995</th>\n",
       "<th>996</th>\n",
       "<th>997</th>\n",
       "<th>998</th>\n",
       "<th>999</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>...</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>1</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>...</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>2</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>...</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>3</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>...</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='font-weight: bold'>4</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>...</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "<td>0</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<p><strong>...</strong></p>"
      ],
      "text/plain": [
       "HaplotypeArray((370264, 1000), dtype=int8)\n",
       "[[0 0 0 ..., 0 0 0]\n",
       " [0 0 0 ..., 0 0 0]\n",
       " [0 0 0 ..., 0 0 0]\n",
       " ..., \n",
       " [0 0 0 ..., 0 0 0]\n",
       " [0 0 0 ..., 0 0 0]\n",
       " [0 0 0 ..., 0 0 0]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = genotypes[:500000, :500].to_haplotypes()\n",
    "ac = H.count_alleles()\n",
    "H = H[ac.is_segregating()]\n",
    "H = H[:370264]\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the PBWT transform, check how compressible these data are already, using a standard compression algorithm (LZ4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zarr.core.Array((370264, 1000), int8, chunks=(679, 1000), order=C)\n",
       "  compression: blosc; compression_opts: {'clevel': 1, 'cname': 'lz4', 'shuffle': 2}\n",
       "  nbytes: 353.1M; nbytes_stored: 10.7M; ratio: 33.1; initialized: 546/546\n",
       "  store: builtins.dict"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_compressed_lz4 = zarr.array(H, chunks=(679, H.shape[1]), compression='blosc', \n",
    "                              compression_opts=dict(cname='lz4', clevel=1, shuffle=2))\n",
    "H_compressed_lz4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as they are, these haplotype data can be compressed down to 10.7M.\n",
    "\n",
    "Now let's built the *PBWT*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.69 s, sys: 248 ms, total: 3.94 s\n",
      "Wall time: 3.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pbwt, ppa, div = build_pbwt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zarr.core.Array((370264, 1000), int8, chunks=(679, 1000), order=C)\n",
       "  compression: blosc; compression_opts: {'clevel': 1, 'cname': 'lz4', 'shuffle': 2}\n",
       "  nbytes: 353.1M; nbytes_stored: 8.2M; ratio: 43.1; initialized: 546/546\n",
       "  store: builtins.dict"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbwt_compressed_lz4 = zarr.array(pbwt, chunks=(679, H.shape[1]), compression='blosc', \n",
    "                                 compression_opts=dict(cname='lz4', clevel=1, shuffle=2))\n",
    "pbwt_compressed_lz4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, *PBWT* is more compressible than the original data, but only marginally, requiring 8.2M rather than 10.7M. This seems at odds with what is reported in Durbin (2014), i.e., that PBWT is many times more compressible than raw haplotypes, so what's going on? \n",
    "\n",
    "I think that a lot of the benefit in terms of compressibility that is reported in Durbin (2014) is actually due to the fact that the haplotype data in the PBWT are transposed relative to the original .gz representation. I.e., If haplotypes are organised one variant per row rather than one haplotype per row, and the underlying bytes are in row-major order, then the data become more compressible as you add more haplotypes, because variants tend to be rare and hence most rows will be composed almost entirely of zeros. If you then permute each row via the PBWT you get a further benefit, because PBWT tends to bring the ones and zeros together, however the added benefit is fairly marginal and most of the gains come simply from the transposed layout.\n",
    "\n",
    "Note that I am using LZ4 here and not the run length encoding used in Durbin (2014), I don't know how much difference that would make.\n",
    "\n",
    "To make use of the PBWT you also need the divergence array, so how compressible is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0, ...,      0,      0,      0],\n",
       "       [     1,      0,      0, ...,      0,      0,      1],\n",
       "       [     2,      0,      0, ...,      0,      1,      2],\n",
       "       ..., \n",
       "       [370261, 369928, 369973, ..., 370259, 370260, 370261],\n",
       "       [370262, 369928, 369973, ..., 370260, 370261, 370262],\n",
       "       [370263, 369928, 369973, ..., 370261, 370262, 370263]], dtype=uint32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zarr.core.Array((370264, 1000), uint32, chunks=(679, 1000), order=C)\n",
       "  compression: blosc; compression_opts: {'clevel': 1, 'cname': 'lz4', 'shuffle': 1}\n",
       "  nbytes: 1.4G; nbytes_stored: 249.8M; ratio: 5.7; initialized: 546/546\n",
       "  store: builtins.dict"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_compressed_lz4 = zarr.array(div, chunks=(679, H.shape[1]), compression='blosc', \n",
    "                                compression_opts=dict(cname='lz4', clevel=1, shuffle=1))\n",
    "div_compressed_lz4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The divergence array is not so compressible with this compression configuration. However Durbin (2014) suggests using a delta filter. Let's try this via the Python LZMA library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 12 ms, total: 29.3 s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lzma\n",
    "filters = [dict(id=lzma.FILTER_DELTA, dist=4),\n",
    "           dict(id=lzma.FILTER_LZMA2, preset=1)]\n",
    "div_compressed_lzma = zarr.array(div, chunks=(679, H.shape[1]), compression='lzma', \n",
    "                                 compression_opts=dict(filters=filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zarr.core.Array((370264, 1000), uint32, chunks=(679, 1000), order=C)\n",
       "  compression: lzma; compression_opts: {'check': 0, 'filters': [{'id': 3, 'dist': 4}, {'id': 33, 'preset': 1}], 'format': 1, 'preset': None}\n",
       "  nbytes: 1.4G; nbytes_stored: 16.0M; ratio: 88.5; initialized: 546/546\n",
       "  store: builtins.dict"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_compressed_lzma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately LZMA is painfully slow, however it does at least demonstrate that the divergence arrays are also highly compressible in principle, here taking 16.0M."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw .ipynb for this post is [here](https://github.com/alimanfoo/alimanfoo.github.io/tree/master/_posts).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
