{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently I've been working on [Zarr](http://zarr.readthedocs.io/en/latest/), a Python package providing chunked, compressed storage for numerical arrays. I've just released [Zarr version 2](http://zarr.readthedocs.io/en/latest/release.html) which adds two new major features: [groups](http://zarr.readthedocs.io/en/latest/tutorial.html#groups) and [filters](http://zarr.readthedocs.io/en/latest/tutorial.html#filters). It also brings support for [Zstandard](TODO) compression via [Blosc](TODO). This post provides a brief tour of what's new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarr 2.1.0\n",
      "blosc 1.11.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zarr; print('zarr', zarr.__version__)\n",
    "from zarr import blosc; print('blosc', blosc.VERSION_STRING)  # TODO __version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups\n",
    "\n",
    "Zarr is heavily inspired by [HDF5](https://www.hdfgroup.org/HDF5/), which provides the capability to organize arrays into groups. Groups can also contain other groups, forming a hierarchy.\n",
    "\n",
    "Here's how to create a group with Zarr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group(/, 0)\n",
       "  store: DictStore"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_group = zarr.group()\n",
    "root_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are familiar with [h5py](http://www.h5py.org/), the API for the Zarr [Group](http://zarr.readthedocs.io/en/latest/api/hierarchy.html#zarr.hierarchy.Group) class is very similar. For example, create a sub-group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group(/foo, 0)\n",
       "  store: DictStore"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo_group = root_group.create_group('foo')\n",
    "foo_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Group](http://zarr.readthedocs.io/en/latest/api/hierarchy.html#zarr.hierarchy.Group) class has various methods for creating arrays within a group, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(/foo/bar, (10000, 10000), float64, chunks=(1000, 1000), order=C)\n",
       "  nbytes: 762.9M; nbytes_stored: 323; ratio: 2476780.2; initialized: 0/100\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: DictStore"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = foo_group.zeros('bar', shape=(10000, 10000), chunks=(1000, 1000))\n",
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group members can be accessed via the square bracket notation, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group(/foo, 1)\n",
       "  arrays: 1; bar\n",
       "  store: DictStore"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_group['foo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(/foo/bar, (10000, 10000), float64, chunks=(1000, 1000), order=C)\n",
       "  nbytes: 762.9M; nbytes_stored: 323; ratio: 2476780.2; initialized: 0/100\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: DictStore"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo_group['bar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple hierarchy levels can also be traversed, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_group['foo/bar'] == foo_group['bar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples above, all data will be stored in memory. However, Zarr can use a variety of other storage layers. For example, data can be stored on the file system, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(/foo/bar, (10000, 10000), float64, chunks=(1000, 1000), order=C)\n",
       "  nbytes: 762.9M; nbytes_stored: 323; ratio: 2476780.2; initialized: 0/100\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: DirectoryStore"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = zarr.DirectoryStore('example')\n",
    "persistent_group = zarr.group(store)\n",
    "a2 = persistent_group.require_dataset('foo/bar', shape=(10000, 10000), chunks=(1000, 1000))\n",
    "a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can also be stored in a [Zip file](http://zarr.readthedocs.io/en/latest/api/storage.html#zarr.storage.ZipStore) (with some limitations), on [S3](http://s3fs.readthedocs.io/en/latest/api.html#s3fs.mapping.S3Map), [HDFS](http://hdfs3.readthedocs.io/en/latest/api.html#hdfs3.mapping.HDFSMap), or any storage system that can by accessed via the [MutableMapping](https://docs.python.org/3/library/collections.abc.html) interface.\n",
    "\n",
    "For more information about groups, see the [groups section of the Zarr tutorial](http://zarr.readthedocs.io/en/latest/tutorial.html#groups) and the [`zarr.hierarchy` API docs](http://zarr.readthedocs.io/en/latest/api/hierarchy.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Zarr 2 also adds support for filters. Filters are arbitrary data transformations that can be applied to data chunks prior to storage. The idea is that, for some kinds of data, certain transformations can help to improve the compression ratio, or provide other useful features such as error checking.\n",
    "\n",
    "There are a few [built-in filter classes](http://zarr.readthedocs.io/en/latest/api/codecs.html) available in Zarr, including delta, scale-offset, quantize, packbits and categorize transformations. Here's a trivial example using the delta filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((100000000,), int64, chunks=(48829,), order=C)\n",
       "  nbytes: 762.9M; nbytes_stored: 11.3M; ratio: 67.4; initialized: 2048/2048\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.arange(100000000)\n",
    "z1a = zarr.array(data)  # no filters\n",
    "z1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((100000000,), int64, chunks=(48829,), order=C)\n",
       "  nbytes: 762.9M; nbytes_stored: 3.6M; ratio: 213.3; initialized: 2048/2048\n",
       "  filters: Delta(dtype=int64)\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1b = zarr.array(data, filters=[zarr.Delta(dtype=data.dtype)])\n",
    "z1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the delta filter improves the compression ratio in this case. \n",
    "\n",
    "For floating point data you can try the quantize or scale-offset filters. Both are lossy for floating point data and allow you to store data with a given precision. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.74674205,  12.21517843,   5.64209159, ...,   9.15225917,\n",
       "        10.78280929,  10.8855431 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.normal(loc=10, scale=2, size=10000000)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10000000,), float64, chunks=(39063,), order=C)\n",
       "  nbytes: 76.3M; nbytes_stored: 67.2M; ratio: 1.1; initialized: 256/256\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2a = zarr.array(data)  # no filters\n",
    "z2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10000000,), float64, chunks=(39063,), order=C)\n",
       "  nbytes: 76.3M; nbytes_stored: 19.4M; ratio: 3.9; initialized: 256/256\n",
       "  filters: Quantize(digits=1, dtype=float64)\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2b = zarr.array(data, filters=[zarr.Quantize(digits=1, dtype=data.dtype)])\n",
    "z2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.75  ,  12.1875,   5.625 , ...,   9.125 ,  10.8125,  10.875 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2b[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10000000,), float64, chunks=(39063,), order=C)\n",
       "  nbytes: 76.3M; nbytes_stored: 17.3M; ratio: 4.4; initialized: 256/256\n",
       "  filters: FixedScaleOffset(scale=10, offset=10, dtype=float64)\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2c = zarr.array(data, filters=[zarr.FixedScaleOffset(offset=10, scale=10, dtype=data.dtype)])\n",
    "z2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.7,  12.2,   5.6, ...,   9.2,  10.8,  10.9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2c[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The packbits filter is intended for use with Boolean arrays, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ...,  True,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.randint(0, 2, size=10000000, dtype=bool)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10000000,), bool, chunks=(156250,), order=C)\n",
       "  nbytes: 9.5M; nbytes_stored: 4.8M; ratio: 2.0; initialized: 64/64\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: dict"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3a = zarr.array(data)  # no filters\n",
    "z3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10000000,), bool, chunks=(156250,), order=C)\n",
       "  nbytes: 9.5M; nbytes_stored: 1.2M; ratio: 8.0; initialized: 64/64\n",
       "  filters: PackBits()\n",
       "  store: dict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3b = zarr.array(data, filters=[zarr.PackBits()], compressor=None)\n",
    "z3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Zarr packbits filter packs Boolean values into single bits, hence the compression ratio of 8.\n",
    "\n",
    "More than one filter can be provided, and compressors are filters too, so you can do some fairly zany things if you want to, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10000000,), float64, chunks=(39063,), order=C)\n",
       "  nbytes: 76.3M; nbytes_stored: 9.1M; ratio: 8.4; initialized: 256/256\n",
       "  filters: Quantize(digits=1, dtype=float64)\n",
       "           Blosc(cname='lz4', clevel=0, shuffle=1)\n",
       "           BZ2(level=9)\n",
       "  store: dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.normal(loc=10, scale=2, size=10000000)\n",
    "zany = zarr.array(data, \n",
    "                  filters=[zarr.Quantize(digits=1, dtype=data.dtype),\n",
    "                           zarr.Blosc(clevel=0, shuffle=blosc.SHUFFLE),\n",
    "                           zarr.BZ2(level=9)],\n",
    "                  compression=None)\n",
    "zany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the built-in filters in Zarr have not been optimized at all yet, I am sure there is much room for performance improvement. The main idea in the Zarr version 2 release is to establish a simple API for developing and integrating new filters, so it is easier to explore different options for new data.\n",
    "\n",
    "For more information about filters, see the [filters section of the Zarr tutorial](TODO) and the [zarr.codecs API docs](TODO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zstandard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other thing I wanted to mention is that Zarr now supports compression with Zstandard. I don't want to say too much here because I'm hoping to write up some detailed benchmark data in a separate blog post soon. But from what I have seen so far, Zstandard is a superb codec, providing very high compression ratios (better than zlib) while maintaining excellent speed for both compression and decompression.\n",
    "\n",
    "Here's how to create a Zarr array using Zstandard compression via Blosc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10000, 10000), float64, chunks=(157, 313), order=C)\n",
       "  nbytes: 762.9M; nbytes_stored: 322; ratio: 2484472.0; initialized: 0/2048\n",
       "  compressor: Blosc(cname='zstd', clevel=5, shuffle=1)\n",
       "  store: dict"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z4 = zarr.zeros(shape=(10000, 10000), \n",
    "                compressor=zarr.Blosc(cname='zstd', clevel=5, shuffle=blosc.SHUFFLE))\n",
    "z4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments and further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest version of Zarr is available from [PyPI]() and [conda-forge](), see the [installation instructions]() for more information. I hope this new release of Zarr is useful, any [feedback or suggestions]() are very welcome as always.  \n",
    "\n",
    "If this is the first time you are reading about Zarr, you might like to check out these previous posts, [To HDF5 and beyond]() and [CPU blues]().\n",
    "\n",
    "Development of Zarr is motivated by our work on the [genomic epidemiology of malaria]() and supported by the [MRC Centre for Genomics and Global Health]().\n",
    "\n",
    "Thanks to [Matthew Rocklin](), [Stephan Hoyer]() and [Francesc Alted]() for much advice and inspiration. As Francesc would say, enjoy data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
