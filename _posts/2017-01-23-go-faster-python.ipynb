{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "This blog post gives an introduction to some techniques for benchmarking, profiling and optimising Python code. If you would like to try the code examples for yourself, you can [download the Jupyter notebook](@@TODO) that this blog post was generated from. To run the notebook, you will need a working Python 3 installation, and will also need to install a couple of Python packages. The way I did that was to first [install miniconda]() into my home directory. I then ran the following commands from the command line:\n",
    "\n",
    "<pre>\n",
    "user@host:~$ export PATH=~/miniconda3/bin/:$PATH\n",
    "user@host:~$ conda create -n go_faster_python python=3.5\n",
    "user@host:~$ source activate go_faster_python\n",
    "(go_faster_python) user@host:~$ conda config --add channels conda-forge\n",
    "(go_faster_python) user@host:~$ conda install cython numpy jupyter line_profiler\n",
    "(go_faster_python) user@host:~$ jupyter notebook &\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "I use Python both for writing software libraries and for interactive data analysis. Python is an **interpreted**, **dynamically-typed** language, with lots of convenient **high-level data structures** like lists, sets, dicts, etc. It's great for getting things done, because no compile step means no delays when developing and testing code or when exploring data. No type declarations means lots of flexibility and less typing (on the keyboard I mean - sorry, bad joke). The high-level data structures mean you can focus on solving the problem rather than low-level nuts and bolts.\n",
    "\n",
    "But the down-side is that Python can be slow. If you have a Python program that's running slowly, what are your options?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking and profiling\n",
    "\n",
    "You've probably heard someone say that **premature optimisation is the root of all evil**. That's a pretty extreme statement, but I think it doesn't hurt to emphasise the experience that many people have, which is that my intuitions for why a piece of code is running slowly are nearly always wrong. If you're going to try and optimise something, you need to do some benchmarking and profiling first, to find out (1) exactly how slow it goes, and (2) where the bottleneck is.\n",
    "\n",
    "To introduce some basic Python benchmarking and profiling tools, let's look at a toy example: computing the sum of 2-dimensional array of integers. Here's some example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [[90, 62, 33, 78, 82],\n",
    "        [37, 31, 0, 72, 32],\n",
    "        [7, 71, 79, 81, 100],\n",
    "        [33, 50, 66, 81, 71],\n",
    "        [87, 26, 54, 78, 81],\n",
    "        [37, 22, 96, 79, 41],\n",
    "        [88, 75, 100, 19, 88],\n",
    "        [24, 72, 59, 33, 92],\n",
    "        [71, 6, 59, 8, 11],\n",
    "        [89, 76, 65, 12, 13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking this isn't an array, it's a list of lists. But using lists is a common and natural way to store data in Python. \n",
    "\n",
    "Here is a naive implementation of a function called `sum2d` to compute the overall sum of a 2-dimensional data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum1d(l):\n",
    "    \"\"\"Compute the sum of a list of numbers.\"\"\"\n",
    "    s = 0\n",
    "    for x in l:\n",
    "        s += x\n",
    "    return s\n",
    "\n",
    "\n",
    "def sum2d(ll):\n",
    "    \"\"\"Compute the sum of a list of lists of numbers.\"\"\"\n",
    "    s = 0\n",
    "    for l in ll:\n",
    "        s += sum1d(l)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the implementation to check it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2817"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum2d(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a bigger dataset to illustrate slow performance. To make a bigger test dataset I'm going to make use of the multiplication operator ('\\*') which when applied to a Python list will create a new list by repeating the elements of the original list. E.g., here's the original list repeated twice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[90, 62, 33, 78, 82],\n",
       " [37, 31, 0, 72, 32],\n",
       " [7, 71, 79, 81, 100],\n",
       " [33, 50, 66, 81, 71],\n",
       " [87, 26, 54, 78, 81],\n",
       " [37, 22, 96, 79, 41],\n",
       " [88, 75, 100, 19, 88],\n",
       " [24, 72, 59, 33, 92],\n",
       " [71, 6, 59, 8, 11],\n",
       " [89, 76, 65, 12, 13],\n",
       " [90, 62, 33, 78, 82],\n",
       " [37, 31, 0, 72, 32],\n",
       " [7, 71, 79, 81, 100],\n",
       " [33, 50, 66, 81, 71],\n",
       " [87, 26, 54, 78, 81],\n",
       " [37, 22, 96, 79, 41],\n",
       " [88, 75, 100, 19, 88],\n",
       " [24, 72, 59, 33, 92],\n",
       " [71, 6, 59, 8, 11],\n",
       " [89, 76, 65, 12, 13]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a bigger dataset by repeating the original data a million times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_data = data * 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataset that is 10,000,000 rows by 5 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the function on these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2817000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum2d(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my laptop this takes a few seconds to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking:  `%time`, `%timeit`, `timeit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start optimising, you need a good estimate of performance as a place to start from, so you know when you've improved something. If you're working in a Jupyter notebook there are a couple of magic commands available which are very helpful for benchmarking: [`%time`](http://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=%25time#magic-time) and [`%timeit`](http://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=%25timeit#magic-timeit). If you're writing a Python script to do the benchmarking, you can use the [`timeit`](https://docs.python.org/3/library/timeit.html) module from the Python standard library.\n",
    "\n",
    "Let's look at the output from [`%time`](http://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=%25time#magic-time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.85 s, sys: 0 ns, total: 2.85 s\n",
      "Wall time: 2.85 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2817000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum2d(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of the output gives the amount of CPU time, broken down into 'user' (your code) and 'sys' (operating system code). The second line gives the wall time, which is the actual amount of time elapsed. Generally the total CPU time and the wall time will be the same, but sometimes not. E.g., if you are benchmarking a multi-threaded program, then wall time may be less than CPU time, because CPU time counts time spent by each CPU separately and adds them together, but the CPUs may actually be working in parallel.\n",
    "\n",
    "One thing to watch out for when benchmarking is that performance can be variable, and may be affected by other processes running on your computer. To see this happen, try running the cell above again, but while it's running, give your computer something else to do at the same time, e.g., play some music, or a video, or just scroll the page up and down a bit.\n",
    "\n",
    "To control for this variation, it's a good idea to benchmark several runs (and avoid the temptation to check your email while it's running). The [`%timeit`](http://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=%25timeit#magic-timeit) magic will automatically benchmark a piece of code several times: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.82 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sum2d(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, using the [`timeit`](https://docs.python.org/3/library/timeit.html) module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8302519290009513, 2.9616496020007617, 2.8006342520002363]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "timeit.repeat(stmt='sum2d(big_data)', repeat=3, number=1, globals=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function profiling: `%prun`, `cProfile`\n",
    "\n",
    "The next thing to do is investigate which part of the code is taking the most time. If you're working in a Jupyter notebook, the [`%prun`](http://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=%25prun#magic-prun) command is a very convenient way to profile some code. Use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun sum2d(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from [`%prun`](http://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=%25prun#magic-prun) pops up in a separate panel, but for this blog post I need to get the output inline, so I'm going to use the [`cProfile`](https://docs.python.org/3/library/profile.html?highlight=cprofile) module from the Python standard library directly, which does the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10000004 function calls in 3.766 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      " 10000000    2.321    0.000    2.321    0.000 <ipython-input-2-12b138a62a96>:1(sum1d)\n",
      "        1    1.445    1.445    3.766    3.766 <ipython-input-2-12b138a62a96>:9(sum2d)\n",
      "        1    0.000    0.000    3.766    3.766 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    3.766    3.766 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "cProfile.run('sum2d(big_data)', sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of things to notice here. \n",
    "\n",
    "First, the time taken to execute the profiling run is quite a bit longer than the time we got when benchmarking earlier. This is because profiling adds some overhead. Generally this doesn't affect the conclusions you would draw about which functions take the most time, but it's something to be aware of.\n",
    "\n",
    "Second, most of the time is being taken up in the `sum1d` function, although a decent amount of time is also being spent within the `sum2d` function. You can see this from the 'tottime' column, which shows the total amount of time spent within a function, **not** including any calls made to other functions. The 'cumtime' column shows the total amount of time spent in a function, including any function calls.\n",
    "\n",
    "Also, you'll notice that there were 10,000,004 function calls. Calling a Python function has some overhead. Maybe the code would go faster if we reduced the number of function calls? Here's a new implementation, combining everything into a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum2d_v2(ll):\n",
    "    \"\"\"Compute the sum of a list of lists of numbers.\"\"\"\n",
    "    s = 0\n",
    "    for l in ll:\n",
    "        for x in l:\n",
    "            s += x\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.17 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sum2d_v2(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit faster. What does the profiler tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4 function calls in 2.212 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    2.212    2.212    2.212    2.212 <ipython-input-14-81d66843d00e>:1(sum2d_v2)\n",
      "        1    0.000    0.000    2.212    2.212 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    2.212    2.212 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run('sum2d_v2(big_data)', sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact we've hit a dead end here, because there is only a single function to profile, and function profiling cannot tell us which lines of code within a function are taking up most time. To get further we need to do some..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line profiling: `%lprun`, `line_profiler`\n",
    "\n",
    "You can do line profiling with a Python module called [`line_profiler`](https://github.com/rkern/line_profiler). This is not part of the Python standard library, so you have to install it separately, e.g., via pip or conda.\n",
    "\n",
    "For convenience, the `line_profiler` module provides a `%lprun` magic command for use in a Jupyter notebook, which can be used as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f sum2d_v2 sum2d_v2(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do the same thing via regular Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import line_profiler\n",
    "l = line_profiler.LineProfiler()\n",
    "l.add_function(sum2d_v2)\n",
    "l.run('sum2d_v2(big_data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 30.7352 s\n",
      "File: <ipython-input-14-81d66843d00e>\n",
      "Function: sum2d_v2 at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def sum2d_v2(ll):\n",
      "     2                                               \"\"\"Compute the sum of a list of lists of numbers.\"\"\"\n",
      "     3         1            2      2.0      0.0      s = 0\n",
      "     4  10000001      2352611      0.2      7.7      for l in ll:\n",
      "     5  60000000     14782948      0.2     48.1          for x in l:\n",
      "     6  50000000     13599659      0.3     44.2              s += x\n",
      "     7         1            0      0.0      0.0      return s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this takes *a lot* longer than with just function profiling or without any profiling. Line profiling adds *a lot* more overhead, and this really can skew benchmarking results sometimes, so it's a good idea after each optimisation you make to benchmark without any profiling at all, as well as running function and line profiling.\n",
    "\n",
    "If you are getting bored waiting for the line profiler to finish, you can interrupt it and it will still output some useful statistics.\n",
    "\n",
    "Note that you have to explicitly tell `line_profiler` which functions to do line profiling within. When using the `%lprun` magic this is done via the `-f` option. \n",
    "\n",
    "Most of the time is spent in the inner for loop, iterating over the inner lists, and performing the addition. Python has a built-in `sum()` function, maybe we could try that? ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum2d_v3(ll):\n",
    "    \"\"\"Compute the sum of a list of lists of numbers.\"\"\"\n",
    "    s = 0\n",
    "    for l in ll:\n",
    "        x = sum(l)\n",
    "        s += x\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.86 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sum2d_v3(big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've shaved off a bit more time. What do the profiling results tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10000004 function calls in 2.657 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      " 10000000    1.338    0.000    1.338    0.000 {built-in method builtins.sum}\n",
      "        1    1.320    1.320    2.657    2.657 <ipython-input-18-baa7cce51590>:1(sum2d_v3)\n",
      "        1    0.000    0.000    2.657    2.657 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    2.657    2.657 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run('sum2d_v3(big_data)', sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 9.35954 s\n",
      "File: <ipython-input-18-baa7cce51590>\n",
      "Function: sum2d_v3 at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def sum2d_v3(ll):\n",
      "     2                                               \"\"\"Compute the sum of a list of lists of numbers.\"\"\"\n",
      "     3         1            3      3.0      0.0      s = 0\n",
      "     4  10000001      2429112      0.2     26.0      for l in ll:\n",
      "     5  10000000      4091269      0.4     43.7          x = sum(l)\n",
      "     6  10000000      2839153      0.3     30.3          s += x\n",
      "     7         1            1      1.0      0.0      return s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import line_profiler\n",
    "l = line_profiler.LineProfiler()\n",
    "l.add_function(sum2d_v3)\n",
    "l.run('sum2d_v3(big_data)')\n",
    "l.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a decent amount of time is being spent inside the built-in `sum()` function, and there's not much we can do about that. But there's also time being spent in the for loop, and in arithmetic. To go further, we need to try..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "\n",
    "For numerical problems, the first port of call is [NumPy](http://www.numpy.org/). Let's use it to solve the sum2d problem. First, let's create a new test dataset, of the same size (10,000,000 rows, 5 columns), but this time using the `np.random.randint()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56, 28, 51, 42, 25],\n",
       "       [24, 71, 30, 56,  4],\n",
       "       [35, 48, 50, 91, 17],\n",
       "       ..., \n",
       "       [30, 78, 50, 97, 55],\n",
       "       [71, 42, 19, 38, 89],\n",
       "       [71, 40, 45, 92, 55]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "big_array = np.random.randint(0, 100, size=(10000000, 5))\n",
    "big_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `big_array` variable is a NumPy array. Here's a few useful properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of dimensions\n",
    "big_array.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000000, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of each dimension\n",
    "big_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data type of each array element\n",
    "big_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of bytes of memory used to store the data\n",
    "big_array.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : False\n",
       "  OWNDATA : True\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  UPDATEIFCOPY : False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some other features of the array\n",
    "big_array.flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy also has its own `np.sum()` function which can operate on N-dimensional arrays. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 30.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sum(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using NumPy is almost two orders of magnitude faster than our own Python sum2d implementation. Where does the speed come from? NumPy's functions are implemented in C, so all of the looping and arithmetic is done in native C code. Also, a NumPy array stores it's data in a single, contiguous block of memory, which can be accessed quickly and efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: array arithmetic\n",
    "\n",
    "There are lots of things you can do with NumPy arrays, without ever having to write a for loop. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([494888839, 494827505, 495034687, 495112245, 494940377])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column sum\n",
    "np.sum(big_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([202, 185, 241, ..., 310, 259, 303])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row sum\n",
    "np.sum(big_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58, 30, 53, 44, 27],\n",
       "       [26, 73, 32, 58,  6],\n",
       "       [37, 50, 52, 93, 19],\n",
       "       ..., \n",
       "       [32, 80, 52, 99, 57],\n",
       "       [73, 44, 21, 40, 91],\n",
       "       [73, 42, 47, 94, 57]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 2 to every array element\n",
    "big_array + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  56, 102,  84,  50],\n",
       "       [ 48, 142,  60, 112,   8],\n",
       "       [ 70,  96, 100, 182,  34],\n",
       "       ..., \n",
       "       [ 60, 156, 100, 194, 110],\n",
       "       [142,  84,  38,  76, 178],\n",
       "       [142,  80,  90, 184, 110]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply every array element by 2\n",
    "big_array * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  56, 102,  84,  50],\n",
       "       [ 48, 142,  60, 112,   8],\n",
       "       [ 70,  96, 100, 182,  34],\n",
       "       ..., \n",
       "       [ 60, 156, 100, 194, 110],\n",
       "       [142,  84,  38,  76, 178],\n",
       "       [142,  80,  90, 184, 110]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add two arrays element-by-element\n",
    "big_array + big_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       ..., \n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more complicated expressions\n",
    "t = (big_array * 2) == (big_array + big_array)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "For when you can't solve a problem with NumPy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://docs.cython.org/en/latest/_images/math/85505aa54782f6e6e6c113b9c562478082c1bbac.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def numpy_approx_pi(n):\n",
    "    pi = np.sqrt(6 * np.sum(1/(np.arange(1, n+1)**2)))\n",
    "    return pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit numpy_approx_pi(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recip_square(i):\n",
    "    s = 1. / i**2\n",
    "    return s\n",
    "\n",
    "\n",
    "def approx_pi(n):\n",
    "    \"\"\"Compute an approximate value of pi.\"\"\"\n",
    "    val = 0\n",
    "    for k in range(1, n+1):\n",
    "        x = recip_square(k)\n",
    "        val += x\n",
    "    pi = (6 * val)**.5\n",
    "    return pi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Cython tutorial: **... remember the golden rule of optimization: Never optimize without having profiled. Let me repeat this: Never optimize without having profiled your code. Your thoughts about which part of your code takes too much time are wrong. At least, mine are always wrong.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun approx_pi(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "# cython: profile=True\n",
    "\n",
    "\n",
    "def recip_square(i):\n",
    "    s = 1. / i**2\n",
    "    return s\n",
    "\n",
    "\n",
    "def approx_pi_cy1(n):\n",
    "    \"\"\"Compute an approximate value of pi.\"\"\"\n",
    "    val = 0\n",
    "    for k in range(1, n+1):\n",
    "        x = recip_square(k)\n",
    "        val += x\n",
    "    pi = (6 * val)**.5\n",
    "    return pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_cy1(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun approx_pi_cy1(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Copy-paste code from above, rename `approx_pi_cy2`\n",
    "* Add -a to inspect Cython's generated code.\n",
    "* Explain yellow.\n",
    "* Break up `recip_square`\n",
    "* Add type to argument `i` in `recip_square`\n",
    "* Add type arguments to other variables in `recip_square` and add `@cython.cdivision(True)` and `cimport cython`\n",
    "* Add line profiling support:\n",
    "\n",
    "<pre>\n",
    "# cython: linetrace=True\n",
    "# cython: binding=True\n",
    "# distutils: define_macros=CYTHON_TRACE_NOGIL=1\n",
    "</pre>\n",
    "\n",
    "* Add `int` type to k and n in `approx_pi_cy2` to optimise for loop\n",
    "* Make `recip_square` a `cdef` function\n",
    "* Add `double` declaration to `val` and return type from `recip_square`\n",
    "* Remove line profiling support\n",
    "* Add `@cython.profile(False)` to `recip_square`\n",
    "* Make `recip_square` an `inline` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "\n",
    "cimport cython\n",
    "\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cdef inline double recip_square(int i):\n",
    "    cdef:\n",
    "        double x, s\n",
    "    x = i**2\n",
    "    s = 1./x\n",
    "    return s\n",
    "\n",
    "\n",
    "def approx_pi_cy2(int n):\n",
    "    \"\"\"Compute an approximate value of pi.\"\"\"\n",
    "    cdef:\n",
    "        long k\n",
    "        double val\n",
    "    val = 0\n",
    "    for k in range(1, n+1):\n",
    "        x = recip_square(k)\n",
    "        val += x\n",
    "    pi = (6 * val)**.5\n",
    "    return pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_cy2(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun approx_pi_cy2(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%lprun -f approx_pi_cy2 approx_pi_cy2(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cython and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain efficient, low-level access to NumPy arrays...\n",
    "\n",
    "* Copy-paste sum2d_v2\n",
    "* Change name, add -a\n",
    "* Add numpy import\n",
    "* Add type declaration to `ll`\n",
    "* Change for loops, introduce typed variables `i` and `j`\n",
    "* Type `s`\n",
    "* Add cython import\n",
    "* Add `boundscheck` and `wraparound` annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "def sum2d_cy(np.int64_t[:, :] ll):\n",
    "    \"\"\"Compute the sum of a list of lists of numbers.\"\"\"\n",
    "    cdef:\n",
    "        int i, j\n",
    "        np.int64_t s\n",
    "    s = 0\n",
    "    for i in range(ll.shape[0]):\n",
    "        for j in range(ll.shape[1]):\n",
    "            s += ll[i, j]\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time sum2d_cy(big_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time np.sum(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further reading..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
