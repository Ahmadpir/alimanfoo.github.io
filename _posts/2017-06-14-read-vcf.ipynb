{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This post gives an introduction to functions for extracting data from [Variant Call Format (VCF)](https://samtools.github.io/hts-specs/VCFv4.3.pdf) files and loading into [NumPy](http://www.numpy.org/) arrays, [pandas](http://pandas.pydata.org/) data frames or [HDF5](https://support.hdfgroup.org/HDF5/) files for ease of analysis. These functions are available in [scikit-allel](http://scikit-allel.readthedocs.io/en/latest/) version 1.1 or later. Any feedback or bug reports welcome.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variant Call Format (VCF)\n",
    "\n",
    "VCF is a widely-used file format for genetic variation data. Here is an example of a small VCF file, based on the example given in the [VCF specification](https://samtools.github.io/hts-specs/VCFv4.3.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.3\n",
      "##reference=file:///seq/references/1000GenomesPilot-NCBI36.fasta\n",
      "##contig=<ID=20,length=62435964,assembly=B36,md5=f126cdf8a6e0c7f379d618ff66beb2da,species=\"Homo sapiens\",taxonomy=x>\n",
      "##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">\n",
      "##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency\">\n",
      "##INFO=<ID=DB,Number=0,Type=Flag,Description=\"dbSNP membership, build 129\">\n",
      "##FILTER=<ID=q10,Description=\"Quality below 10\">\n",
      "##FILTER=<ID=s50,Description=\"Less than 50% of samples have data\">\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
      "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth\">\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tNA00001\tNA00002\tNA00003\n",
      "20\t14370\trs6054257\tG\tA\t29\tPASS\tDP=14;AF=0.5;DB\tGT:DP\t0/0:1\t0/1:8\t1/1:5\n",
      "20\t17330\t.\tT\tA\t3\tq10\tDP=11;AF=0.017\tGT:DP\t0/0:3\t0/1:5\t0/0:41\n",
      "20\t1110696\trs6040355\tA\tG,T\t67\tPASS\tDP=10;AF=0.333,0.667;DB\tGT:DP\t0/2:6\t1/2:0\t2/2:4\n",
      "20\t1230237\t.\tT\t.\t47\tPASS\tDP=13\tGT:DP\t0/0:7\t0/0:4\t./.:.\n",
      "20\t1234567\tmicrosat1\tGTC\tG,GTCT\t50\tPASS\tDP=9\tGT:DP\t0/1:4\t0/2:2\t1/1:3\n"
     ]
    }
   ],
   "source": [
    "with open('example.vcf', mode='r') as vcf:\n",
    "    print(vcf.read(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A VCF file begins with a number of meta-information lines, which start with two hash ('##') characters. Then there is a single header line beginning with a single hash ('#') character. After the header line there are data lines, with each data line describing a genetic variant at a particular position relative to the reference genome of whichever species you are studying. Each data line is divided into fields separated by tab characters. There are 9 fixed fields, labelled \"CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\" and \"FORMAT\". Following these are fields containing data about samples. \n",
    "\n",
    "For example, the first data line in the file above describes a variant on chromosome 20 at position 14370 relative to the B36 assembly of the human genome. The reference allele is 'G' and the alternate allele is 'A', so this is a single nucleotide polymorphism (SNP). In this file there are three fields with data about samples labelled 'NA00001', 'NA00002' and 'NA00003'. The genotype call in the first sample is '0/0', meaning that individual 'NA0001' is homozygous for the reference allele at this position. The genotype call for the second sample is '0/1' (you may need to scroll across to see this), which means that individual 'NA00002' is heterozygous for the reference and alternate alleles at this position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy/pandas/HDF5/...\n",
    "\n",
    "There are a number of software tools that can read VCF files and perform various analyses. However, if your dataset is large and/or you need to do some bespoke analysis, then it can be faster and more convenient to first extract the necessary data from the VCF file and load into a more efficient storage container.\n",
    "\n",
    "For analysis and plotting of numerical data in Python, it is very convenient to load data into [NumPy arrays](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html). A NumPy array is an in-memory data structure that provides support for fast arithmetic and data manipulation. For analysing tables of data, [pandas DataFrames](https://pandas.pydata.org/pandas-docs/stable/dsintro.html) provide useful features such as querying, aggregation and joins. When data are too large to fit into main memory, [HDF5 files](http://docs.h5py.org/en/latest/quick.html) and [Zarr arrays](http://zarr.readthedocs.io/en/latest/tutorial.html) can provide fast on-disk storage and retrieval of numerical arrays. \n",
    "\n",
    "[scikit-allel](http://scikit-allel.readthedocs.io/en/latest/) is a Python package intended to enable exploratory analysis of large-scale genetic variation data. Version 1.1.0 of scikit-allel adds some new functions for extracting data from VCF files and loading the data into NumPy arrays, pandas DataFrames or HDF5 files. Once you have extracted these data, there are many analyses that can be run interactively on a commodity laptop or desktop computer, even with large-scale datasets from population resequencing studies. To give a flavour of what analyses can be done, there are a few previous articles on my blog, touching on topics including [variant and sample QC](http://alimanfoo.github.io/2016/06/10/scikit-allel-tour.html), [allele frequency differentiation](http://alimanfoo.github.io/2015/09/21/estimating-fst.html), [population structure](http://alimanfoo.github.io/2015/09/28/fast-pca.html), and [genetic crosses](http://alimanfoo.github.io/2017/02/14/mendelian-transmission.html).\n",
    "\n",
    "Until now, getting data out of VCF files and into NumPy etc. has been a bit of a pain point. Hopefully the new scikit-allel functions will make this a bit less of a hurdle. Let's take a look at the new functions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`read_vcf()`](@@TODO)\n",
    "\n",
    "Let's start with the scikit-allel function [`read_vcf()`](@@TODO). First, some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0b5\n"
     ]
    }
   ],
   "source": [
    "# import scikit-allel\n",
    "import allel\n",
    "# check which version is installed\n",
    "print(allel.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the example VCF file shown above, using default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callset = allel.read_vcf('example.vcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `callset` object returned by `read_vcf()` is a Python dictionary (`dict`). It contains several NumPy arrays, each of which can be accessed via a key. Here are the available keys: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calldata/GT',\n",
       " 'samples',\n",
       " 'variants/ALT',\n",
       " 'variants/CHROM',\n",
       " 'variants/FILTER_PASS',\n",
       " 'variants/ID',\n",
       " 'variants/POS',\n",
       " 'variants/QUAL',\n",
       " 'variants/REF']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(callset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'samples' array contains sample identifiers extracted from the header line in the VCF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NA00001', 'NA00002', 'NA00003'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All arrays with keys beginning 'variants/' come from the fixed fields in the VCF file. For example, here is the data from the 'CHROM' field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20', '20', '20', '20', '20'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['variants/CHROM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the data from the 'POS' field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14370,   17330, 1110696, 1230237, 1234567], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['variants/POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the data from the 'QUAL' field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 29.,   3.,  67.,  47.,  50.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['variants/QUAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All arrays with keys beginning 'calldata/' come from the sample fields in the VCF file. For example, here are the actual genotype calls from the 'GT' field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 1,  1]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[ 0,  2],\n",
       "        [ 1,  2],\n",
       "        [ 2,  2]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [-1, -1]],\n",
       "\n",
       "       [[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 1,  1]]], dtype=int8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['calldata/GT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the -1 values for one of the genotype calls. By default scikit-allel uses -1 to indicate a missing value for any array with a signed integer data type (although you can change this if you want).\n",
    "\n",
    "Because working with genotype calls is a very common task, scikit-allel has a special [`GenotypeArray`](@@TODO) class which adds some convenient functionality to an array of genotype calls. To use this class, pass the raw NumPy array into the `GenotypeArray` class constructor, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeArray shape=(5, 3, 2) dtype=int8&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">1/2</td><td style=\"text-align: center\">2/2</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">3</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">./.</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">4</th><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">1/1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeArray shape=(5, 3, 2) dtype=int8>\n",
       "0/0 0/1 1/1\n",
       "0/0 0/1 0/0\n",
       "0/2 1/2 2/2\n",
       "0/0 0/0 ./.\n",
       "0/1 0/2 1/1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = allel.GenotypeArray(callset['calldata/GT'])\n",
    "gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the things that the `GenotypeArray` class does is provide a slightly more visually-appealing representation when used in a Jupyter notebook, as can be seen above. There are also methods for making various computations over the genotype calls. For example, the `is_het()` method locates all heterozygous genotype calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [ True,  True, False],\n",
       "       [False, False, False],\n",
       "       [ True,  True, False]], dtype=bool)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.is_het()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give another example, the `count_het()` method will count heterozygous calls, summing over variants (axis=0) or samples (axis=1) if requested. E.g., to count the number of het calls per variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.count_het(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more example, here is how to perform an allele count, i.e., count the number times each allele (0=reference, 1=first alternate, 2=second alternate, etc.) is observed for each variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;AlleleCountsArray shape=(5, 3) dtype=int32&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">3</td><td style=\"text-align: center\">3</td><td style=\"text-align: center\">0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">5</td><td style=\"text-align: center\">1</td><td style=\"text-align: center\">0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">1</td><td style=\"text-align: center\">1</td><td style=\"text-align: center\">4</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">3</th><td style=\"text-align: center\">4</td><td style=\"text-align: center\">0</td><td style=\"text-align: center\">0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">4</th><td style=\"text-align: center\">2</td><td style=\"text-align: center\">3</td><td style=\"text-align: center\">1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<AlleleCountsArray shape=(5, 3) dtype=int32>\n",
       "3 3 0\n",
       "5 1 0\n",
       "1 1 4\n",
       "4 0 0\n",
       "2 3 1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = gt.count_alleles()\n",
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fields\n",
    "\n",
    "VCF files can often contain many fields of data, and you may only need to extract some of them to perform a particular analysis. You can select which fields to extract by passing a list of strings as the **fields** parameter. For example, let's extract the 'DP' field from within the 'INFO' field, and let's also extract the 'DP' field from the sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calldata/DP', 'variants/DP']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['variants/DP', 'calldata/DP'])\n",
    "sorted(callset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the data that we just extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 11, 10, 13,  9], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['variants/DP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  8,  5],\n",
       "       [ 3,  5, 41],\n",
       "       [ 6,  0,  4],\n",
       "       [ 7,  4, -1],\n",
       "       [ 4,  2,  3]], dtype=int16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['calldata/DP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose these two fields to illustrate the point that sometimes the same field name (e.g., 'DP') can be used both within the INFO field of a VCF and also within the sample data. When selecting fields, to make sure there is no ambiguity, you can include a prefix which is either 'variants/' or 'calldata/'. For example, if you provide 'variants/DP', then the `read_vcf()` function will look for an INFO field named 'DP'. If you provide 'calldata/DP' then `read_vcf()` will look for a FORMAT field named 'DP' within the sample data. \n",
    "\n",
    "If you are feeling lazy, you can drop the 'variants/' and 'calldata/' prefixes, in which case `read_vcf()` will assume you mean 'variants/' if there is any ambiguity. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calldata/GT', 'variants/DP']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['DP', 'GT'])\n",
    "sorted(callset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to extract absolutely everything from a VCF file, then you can provide a special value ``'*'`` as the **fields** parameter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calldata/DP',\n",
       " 'calldata/GT',\n",
       " 'samples',\n",
       " 'variants/AF',\n",
       " 'variants/ALT',\n",
       " 'variants/CHROM',\n",
       " 'variants/DB',\n",
       " 'variants/DP',\n",
       " 'variants/FILTER_PASS',\n",
       " 'variants/FILTER_q10',\n",
       " 'variants/FILTER_s50',\n",
       " 'variants/ID',\n",
       " 'variants/POS',\n",
       " 'variants/QUAL',\n",
       " 'variants/REF',\n",
       " 'variants/is_snp',\n",
       " 'variants/numalt',\n",
       " 'variants/svlen']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields='*')\n",
    "sorted(callset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "NumPy arrays can have various data types, including signed integers ('int8', 'int16', 'int32', 'int64'), unsigned integers ('uint8', 'uint16', 'uint32', 'uint64'), floating point numbers ('float32', 'float64'), variable length strings ('object') and fixed length strings (e.g., 'S4' for a 4-character ASCII string). scikit-allel will try to choose a sensible default data type for the fields you want to extract, based on the meta-information in the VCF file, but you can override these via the **types** parameter. \n",
    "\n",
    "For example, by default the 'DP' INFO field is loaded into a 32-bit integer array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 11, 10, 13,  9], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['DP'])\n",
    "callset['variants/DP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know the maximum value this field is going to contain, to save some memory you could choose a 16-bit integer array instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 11, 10, 13,  9], dtype=int16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['DP'], types={'DP': 'int16'})\n",
    "callset['variants/DP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose a floating-point data type, even for fields that are declared as type 'Integer' in the VCF meta-information, and vice versa. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.,  11.,  10.,  13.,   9.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['DP'], types={'DP': 'float32'})\n",
    "callset['variants/DP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fields containing textual data, there are two choices for data type. By default, scikit-allel will use an 'object' data type, which means that values are stored as an array of Python strings. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['G', 'T', 'A', 'T', 'GTC'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['REF'])\n",
    "callset['variants/REF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of using 'object' dtype is that strings can be of any length. Alternatively, you can use a fixed-length string dtype, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'G', b'T', b'A', b'T', b'GTC'], \n",
       "      dtype='|S3')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['REF'], types={'REF': 'S3'})\n",
    "callset['variants/REF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that fixed-length string dtypes will cause any string values longer than the requested number of characters to be truncated. I.e., there can be some data loss. E.g., if using a single-character string for the 'REF' field, the correct value of 'GTC' for the final variant will get truncated to 'G':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'G', b'T', b'A', b'T', b'G'], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', fields=['REF'], types={'REF': 'S1'})\n",
    "callset['variants/REF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers\n",
    "\n",
    "Some fields like 'ALT', 'AC' and 'AF' can have a variable number of values. I.e., each variant may have a different number of data values for these fields. One trade-off you have to make when loading data into NumPy arrays is that you cannot have arrays with a variable number of items per row. Rather, you have to fix the maximum number of possible items. While you lose some flexibility, you gain speed of access.\n",
    "\n",
    "For fields like 'ALT', scikit-allel will choose a default number of expected values, which is set at 3. E.g., here is what you get by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A', '', ''],\n",
       "       ['A', '', ''],\n",
       "       ['G', 'T', ''],\n",
       "       ['', '', ''],\n",
       "       ['G', 'GTCT', '']], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf')\n",
    "callset['variants/ALT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, 3 is more that we need, because no variant has more than 2 ALT values. However, some VCF files (especially those including INDELs) may have more than 3 ALT values. \n",
    "\n",
    "If you need to increase or decrease the expected number of values for any field, you can do this via the **numbers** parameter. E.g., increase the number of ALT values to 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A', '', '', '', ''],\n",
       "       ['A', '', '', '', ''],\n",
       "       ['G', 'T', '', '', ''],\n",
       "       ['', '', '', '', ''],\n",
       "       ['G', 'GTCT', '', '', '']], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', numbers={'ALT': 5})\n",
    "callset['variants/ALT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some care is needed here, because if you choose a value that is lower than the maximum number of values in the VCF file, then any extra values will not get extracted. E.g., the following would be fine if all variants were biallelic, but would lose information for any multi-allelic variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'A', 'G', '', 'G'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', numbers={'ALT': 1})\n",
    "callset['variants/ALT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genotype ploidy\n",
    "\n",
    "By default, scikit-allel assumes you are working with a diploid organism, and so expects to parse out 2 alleles for each genotype call. If you are working with an organism with some other ploidy, you can change the expected number of alleles via the **numbers** parameter.\n",
    "\n",
    "For example, here is an example VCF with tetraploid genotype calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.3\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tsample1\tsample2\tsample3\n",
      "20\t14370\t.\tG\tA\t.\t.\t.\tGT\t0/0/0/0\t0/0/0/1\t0/0/1/1\n",
      "20\t17330\t.\tT\tA,C,G\t.\t.\t.\tGT\t1/1/2/2\t0/1/2/3\t3/3/3/3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('example_polyploid.vcf', mode='r') as f:\n",
    "    print(f.read(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to indicate the ploidy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 1]],\n",
       "\n",
       "       [[1, 1, 2, 2],\n",
       "        [0, 1, 2, 3],\n",
       "        [3, 3, 3, 3]]], dtype=int8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example_polyploid.vcf', numbers={'GT': 4})\n",
    "callset['calldata/GT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown earlier for diploid calls, the `GenotypeArray` class can provide some extra functionality over a plain NumPy array, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeArray shape=(2, 3, 4) dtype=int8&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0/0/0</td><td style=\"text-align: center\">0/0/0/1</td><td style=\"text-align: center\">0/0/1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">1/1/2/2</td><td style=\"text-align: center\">0/1/2/3</td><td style=\"text-align: center\">3/3/3/3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeArray shape=(2, 3, 4) dtype=int8>\n",
       "0/0/0/0 0/0/0/1 0/0/1/1\n",
       "1/1/2/2 0/1/2/3 3/3/3/3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = allel.GenotypeArray(callset['calldata/GT'])\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True],\n",
       "       [ True,  True, False]], dtype=bool)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.is_het()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;AlleleCountsArray shape=(2, 4) dtype=int32&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th><th style=\"text-align: center\">3</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">9</td><td style=\"text-align: center\">3</td><td style=\"text-align: center\">0</td><td style=\"text-align: center\">0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">1</td><td style=\"text-align: center\">3</td><td style=\"text-align: center\">3</td><td style=\"text-align: center\">5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<AlleleCountsArray shape=(2, 4) dtype=int32>\n",
       "9 3 0 0\n",
       "1 3 3 5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = gt.count_alleles()\n",
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region\n",
    "\n",
    "You can extract data for only a specific chromosome or genome region via the **region** parameter. The value of the parameter should be a region string of the format '{chromosome}:{begin}-{end}', just like you would give to tabix or samtools. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1110696, 1230237], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', region='20:1000000-1231000')\n",
    "callset['variants/POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, scikit-allel will try to use tabix to extract the data from the requested region. If tabix is not available on your system or the VCF file has not been tabix indexed, scikit-allel will fall back to scanning through the VCF file from the beginning, which may be slow. If you have tabix installed but it is in a non-standard location, you can specify the path to the tabix executable via the **tabix** parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples\n",
    "\n",
    "You can extract data for only specific samples via the **samples** parameter. E.g., extract data for samples 'NA00001' and 'NA00003':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NA00001', 'NA00003'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset = allel.read_vcf('example.vcf', samples=['NA00001', 'NA00003'])\n",
    "callset['samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeArray shape=(5, 2, 2) dtype=int8&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">2/2</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">3</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">./.</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">4</th><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">1/1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeArray shape=(5, 2, 2) dtype=int8>\n",
       "0/0 1/1\n",
       "0/0 0/0\n",
       "0/2 2/2\n",
       "0/0 ./.\n",
       "0/1 1/1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allel.GenotypeArray(callset['calldata/GT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the genotype array now only has two columns, corresponding to the two samples requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`vcf_to_npz()`](@@TODO)\n",
    "\n",
    "NumPy arrays are stored in main memory (a.k.a., RAM), which means that as soon as you end your Python session or restart your Jupyter notebook kernel, any data stored in a NumPy array will be lost. \n",
    "\n",
    "If your VCF file is not too big, you can extract data from the file into NumPy arrays then save those arrays to disk via the [`vcf_to_npz()`](@@TODO) function. This function has most of the same parameters as the `read_vcf()` function, except that you also specify an output path, which is the name of the file you want to save the extracted data to. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allel.vcf_to_npz('example.vcf', 'example.npz', fields='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This extraction only needs to be done once, then you can load the data any time directly into NumPy arrays via the NumPy [`load()`](@@TODO) function, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x7f10b4180160>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "callset = np.load('example.npz')\n",
    "callset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calldata/DP',\n",
       " 'calldata/GT',\n",
       " 'samples',\n",
       " 'variants/AF',\n",
       " 'variants/ALT',\n",
       " 'variants/CHROM',\n",
       " 'variants/DB',\n",
       " 'variants/DP',\n",
       " 'variants/FILTER_PASS',\n",
       " 'variants/FILTER_q10',\n",
       " 'variants/FILTER_s50',\n",
       " 'variants/ID',\n",
       " 'variants/POS',\n",
       " 'variants/QUAL',\n",
       " 'variants/REF',\n",
       " 'variants/is_snp',\n",
       " 'variants/numalt',\n",
       " 'variants/svlen']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(callset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14370,   17330, 1110696, 1230237, 1234567], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['variants/POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 1,  1]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[ 0,  2],\n",
       "        [ 1,  2],\n",
       "        [ 2,  2]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [-1, -1]],\n",
       "\n",
       "       [[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 1,  1]]], dtype=int8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callset['calldata/GT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although the data have been saved to disk, all of the data must be loaded into main memory first during the extraction process, so this function is not suitable if you have a dataset that is too large to fit into main memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`vcf_to_hdf5()`](@@TODO)\n",
    "\n",
    "For large datasets, the [`vcf_to_hdf5()`](@@TODO) function is available. This function again takes similar parameters to `read_vcf()`, but will store extracted data into an HDF5 file stored on disk. The extraction process works through the VCF file in chunks, and so the entire dataset is never loaded entirely into main memory. A bit further below I give worked examples with some large datasets, but for now here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allel.vcf_to_hdf5('example.vcf', 'example.h5', fields='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved data can be accessed via the [`h5py`](@@TODO) library, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"example.h5\" (mode r)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "callset = h5py.File('example.h5', mode='r')\n",
    "callset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one difference to be aware of here is that accessing data via a key like 'variants/POS' does not return a NumPy array, instead you get an HDF5 dataset object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"POS\": shape (5,), type \"<i4\">"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = callset['variants/POS']\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset object is useful because you can then load all or only part of the underlying data into main memory via slicing. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  17330, 1110696], dtype=int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load second to fourth items into NumPy array\n",
    "pos[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14370,   17330, 1110696, 1230237, 1234567], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all items into NumPy array\n",
    "pos[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is particularly useful for the large data coming from the sample fields, e.g., the genotype calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"GT\": shape (5, 3, 2), type \"|i1\">"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = callset['calldata/GT']\n",
    "gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these data you can use slicing to pull out particular rows or columns without having to load all data into memory. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 2],\n",
       "        [1, 2],\n",
       "        [2, 2]]], dtype=int8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load genotype calls into memory for second to fourth variants, all samples\n",
    "gt[1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[0, 2],\n",
       "        [1, 2]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 1],\n",
       "        [0, 2]]], dtype=int8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load genotype calls into memory for all variants, first and second samples\n",
    "gt[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 1,  1]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[ 0,  2],\n",
       "        [ 1,  2],\n",
       "        [ 2,  2]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [-1, -1]],\n",
       "\n",
       "       [[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 1,  1]]], dtype=int8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all genotype calls into memory\n",
    "gt[:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`vcf_to_zarr()`](@@TODO)\n",
    "\n",
    "An alternative to HDF5 is a new storage library called [Zarr](@@TODO). Currently there is only a Python implementation of Zarr, whereas you can access HDF5 files using a variety of different programming languages, so if you need portability then HDF5 is a better option. However, if you know you're only going to be using Python, then Zarr may be worth trying. In general it is a bit faster than HDF5, provides more storage and compression options, and also plays better with parellel computing libraries like [Dask](@@TODO). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allel.vcf_to_zarr('example.vcf', 'example.zarr', fields='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved data can be accessed via the [`zarr`](@@TODO) library, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group(/, 3)\n",
       "  arrays: 1; samples\n",
       "  groups: 2; calldata, variants\n",
       "  store: DirectoryStore"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zarr\n",
    "callset = zarr.open_group('example.zarr', mode='r')\n",
    "callset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with h5py, you can use slicing to access regions of the data, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(/variants/POS, (5,), int32, chunks=(65536,), order=C)\n",
       "  nbytes: 20; nbytes_stored: 1.5K; ratio: 0.0; initialized: 1/1\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: DirectoryStore"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = callset['variants/POS']\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  17330, 1110696], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14370,   17330, 1110696, 1230237, 1234567], dtype=int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(/calldata/GT, (5, 3, 2), int8, chunks=(65536, 3, 2), order=C)\n",
       "  nbytes: 30; nbytes_stored: 2.2K; ratio: 0.0; initialized: 1/1\n",
       "  compressor: Blosc(cname='lz4', clevel=5, shuffle=1)\n",
       "  store: DirectoryStore"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = callset['calldata/GT']\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 2],\n",
       "        [1, 2],\n",
       "        [2, 2]]], dtype=int8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[0, 2],\n",
       "        [1, 2]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 1],\n",
       "        [0, 2]]], dtype=int8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 1,  1]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  1],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[ 0,  2],\n",
       "        [ 1,  2],\n",
       "        [ 2,  2]],\n",
       "\n",
       "       [[ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [-1, -1]],\n",
       "\n",
       "       [[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 1,  1]]], dtype=int8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`vcf_to_dataframe()`](@@TODO)\n",
    "\n",
    "@@TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`vcf_to_csv()`](@@TODO)\n",
    "\n",
    "@@TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`vcf_to_recarray()`](@@TODO)\n",
    "\n",
    "@@TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human 1000 genomes phase 3\n",
    "\n",
    "@@TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pf3k (Plasmodium falciparum) release 5.1\n",
    "\n",
    "@@TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other datasets\n",
    "\n",
    "### Ag1000G (Anopheles gambiae) phase 1 AR3 release\n",
    "\n",
    "@@TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "@@TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-script: changes from `vcfnp`\n",
    "\n",
    "The new functions available in `scikit-allel` supercede a package I previously wrote for extracting data from VCF files called [`vcfnp`](@@TODO). I rewrote this functionality from the ground up and ported the functionality to `scikit-allel` for two main reasons. Firstly, `vcfnp` was slow and so you needed a cluster to parse big VCF files, which is obviously a pain. The new functions in `scikit-allel` should be up to ~40 times faster. Secondly, the `vcfnp` API was somewhat complicated, requiring three separate steps to get data from VCF into an HDF5 file or Zarr store. The new functions in `scikit-allel` hopefully simplify this process, enabling data to be extracted from VCF and loaded into any of a variety of storage containers via a single function call.\n",
    "\n",
    "If you previously used `vcfnp` here are a few notes on some of the things that have changed.\n",
    "\n",
    "* No need for separate function calls to extract data from variants and calldata fields, both can be extracted via a single call to `read_vcf()` or any of the `vcf_to_...()` functions described above.\n",
    "* Data can be extracted from VCF and loaded into HDF5 with a single function call to `vcf_to_hdf5()`; i.e., no need to first extract parts of the data out to .npy files then load into HDF5.\n",
    "* No need to use a cluster or do any parallelisation, it should be possible to run `vcf_to_hdf5()` or `vcf_to_zarr()` on a whole VCF on a half-decent desktop or laptop computer, although big VCF files might take a couple of hours and require a reasonably large hard disk.\n",
    "* The default NumPy data type for string fields has changed to use 'object' dtype, which means that strings of any length will be stored automatically (i.e., no need to configure separate dtypes for each string field) and there will be no truncation of long strings.\n",
    "* Previously in `vcfnp` the genotype calls were extracted into a special field called 'genotype' separate from the 'GT' calldata field if requested. In `scikit-allel` the default behaviour is to parse the 'GT' field as a 3-dimensional integer array and return simply as 'calldata/GT'. If you really want to process the 'GT' field as a string then you can override this by setting the type for 'calldata/GT' to 'S3' or 'object'.\n",
    "* The \"arity\" argument in `vcfnp` is instead called \"numbers\" in scikit-allel, to match better with the terminology used in VCF meta-information headers.\n",
    "* Genotype ploidy is now specified via the \"numbers\" argument, there is no special \"ploidy\" argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
